{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Z7jeJTpjb8i7",
        "slB3-cpCcCjm",
        "JlLImDLYcPk1",
        "U-VEOVFXK2UN",
        "nF0MDXNBfDgI",
        "Zm2YstyufALz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the dependencies\n"
      ],
      "metadata": {
        "id": "Z7jeJTpjb8i7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Spc5CimoAyj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce744642-26fa-4cd1-c376-53f0b008b8cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import tensorflow.compat.v1 as tf \n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plot\n",
        "from sklearn.model_selection import train_test_split\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network"
      ],
      "metadata": {
        "id": "LNdul_1XplkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading data\n"
      ],
      "metadata": {
        "id": "slB3-cpCcCjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "X_train = pd.read_csv(\"/content/drive/MyDrive/Dataset/Challenge/X_train.csv\", sep= \";\")\n",
        "Y_train = pd.read_csv(\"/content/drive/MyDrive/Dataset/Challenge/y_train.csv\", sep= \";\")\n",
        "X_test = pd.read_csv(\"/content/drive/MyDrive/Dataset/Challenge/X_test.csv\", sep= \";\")\n"
      ],
      "metadata": {
        "id": "bX9Du0yJBOUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print datasets\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "f_V4bKFAu68o",
        "outputId": "ed3a8f53-2465-4713-f74f-0144350862d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Id                                            Caption\n",
              "0      2  de mourir avant l'heure\\n de ne plus revoir me...\n",
              "1      3  la maladie pour les autres et pour moi\\n et le...\n",
              "2      4  Comment vont s'en sortir ceux qui sont mal ou ...\n",
              "3      6  Inquiétude pour la santé de mes proches, pour ...\n",
              "4      7                Bien entendu contracter la maladie,\n",
              "..   ...                                                ...\n",
              "480  591                     avoir une forme grave du civid\n",
              "481  592  Inquiétude de ne pas retrouver une liberté d'a...\n",
              "482  594  L'incertitude dans laquelle nous sommes. \\n Ne...\n",
              "483  595  inquiétude normale face à une épidémie, craint...\n",
              "484  596    Que les autres ne respectent pas les barrières.\n",
              "\n",
              "[485 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad3de160-bc7c-4c7c-b799-f58979de8b26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>de mourir avant l'heure\\n de ne plus revoir me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>la maladie pour les autres et pour moi\\n et le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Comment vont s'en sortir ceux qui sont mal ou ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>Inquiétude pour la santé de mes proches, pour ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>Bien entendu contracter la maladie,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>591</td>\n",
              "      <td>avoir une forme grave du civid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>592</td>\n",
              "      <td>Inquiétude de ne pas retrouver une liberté d'a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>594</td>\n",
              "      <td>L'incertitude dans laquelle nous sommes. \\n Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>595</td>\n",
              "      <td>inquiétude normale face à une épidémie, craint...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>596</td>\n",
              "      <td>Que les autres ne respectent pas les barrières.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>485 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad3de160-bc7c-4c7c-b799-f58979de8b26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad3de160-bc7c-4c7c-b799-f58979de8b26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad3de160-bc7c-4c7c-b799-f58979de8b26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.rename(columns={'Id ':'Id'},inplace = True)\n",
        "Id = X_test['Id']"
      ],
      "metadata": {
        "id": "MHohbRverDyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = Y_train.drop(['Id'],axis=1)"
      ],
      "metadata": {
        "id": "gMXOvGCqc8Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data building\n"
      ],
      "metadata": {
        "id": "JlLImDLYcPk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenation before vectorization\n",
        "data = pd.concat((X_train,X_test), axis = 0)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "nzQ0UWREPaji",
        "outputId": "cb627402-260a-45c5-ebdd-dbc09e80e195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Id                                            Caption\n",
              "0      2  de mourir avant l'heure\\n de ne plus revoir me...\n",
              "1      3  la maladie pour les autres et pour moi\\n et le...\n",
              "2      4  Comment vont s'en sortir ceux qui sont mal ou ...\n",
              "3      6  Inquiétude pour la santé de mes proches, pour ...\n",
              "4      7                Bien entendu contracter la maladie,\n",
              "..   ...                                                ...\n",
              "152  798  - De rester enfermée,\\n -  loin des amies ou a...\n",
              "153  799  L'atteinte à nos libertés (appli stop-covi, et...\n",
              "154  800                                      risque mortel\n",
              "155  801  ne pas pouvoir sortir\\n ne pas voir mes petits...\n",
              "156  802                              la contagion bien sûr\n",
              "\n",
              "[642 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43eb7a65-a3f3-4ae9-bff0-26963ff043c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>de mourir avant l'heure\\n de ne plus revoir me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>la maladie pour les autres et pour moi\\n et le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Comment vont s'en sortir ceux qui sont mal ou ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>Inquiétude pour la santé de mes proches, pour ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>Bien entendu contracter la maladie,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>798</td>\n",
              "      <td>- De rester enfermée,\\n -  loin des amies ou a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>799</td>\n",
              "      <td>L'atteinte à nos libertés (appli stop-covi, et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>800</td>\n",
              "      <td>risque mortel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>801</td>\n",
              "      <td>ne pas pouvoir sortir\\n ne pas voir mes petits...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>802</td>\n",
              "      <td>la contagion bien sûr</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>642 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43eb7a65-a3f3-4ae9-bff0-26963ff043c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43eb7a65-a3f3-4ae9-bff0-26963ff043c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43eb7a65-a3f3-4ae9-bff0-26963ff043c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorization\n",
        "\n",
        "cv = CountVectorizer()\n",
        "\n",
        "cv_matrix = cv.fit_transform(data['Caption'])\n",
        "\n",
        "# create document term matrix\n",
        "df_dtm = pd.DataFrame(cv_matrix.toarray(), index=data['Id'].values, columns=cv.get_feature_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KotK08ilHG9T",
        "outputId": "b143a30f-0b75-40e0-ea4d-c07410b4c15f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dtm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tBsYeVQ7KkaP",
        "outputId": "c4112fb2-5eac-45d0-ba23-7b5dde3febf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     05  10  11  12e  15  17  19  1la  1m  1ère  ...  évidentes  évitant  \\\n",
              "2     0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "3     0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "4     0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "6     0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "7     0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "..   ..  ..  ..  ...  ..  ..  ..  ...  ..   ...  ...        ...      ...   \n",
              "798   0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "799   0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "800   0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "801   0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "802   0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "\n",
              "     éviter  évolution  événement  événements  êtes  être  êtres  ùmlù  \n",
              "2         0          0          0           0     0     0      0     0  \n",
              "3         0          0          0           0     0     0      0     0  \n",
              "4         0          0          0           0     0     0      0     0  \n",
              "6         0          0          0           0     0     0      0     0  \n",
              "7         0          0          0           0     0     0      0     0  \n",
              "..      ...        ...        ...         ...   ...   ...    ...   ...  \n",
              "798       0          0          0           0     0     1      0     0  \n",
              "799       0          0          0           0     0     0      0     0  \n",
              "800       0          0          0           0     0     0      0     0  \n",
              "801       0          0          0           0     0     0      0     0  \n",
              "802       0          0          0           0     0     0      0     0  \n",
              "\n",
              "[642 rows x 2663 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e9958eb-1150-459e-b879-98bae2750f8a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>05</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12e</th>\n",
              "      <th>15</th>\n",
              "      <th>17</th>\n",
              "      <th>19</th>\n",
              "      <th>1la</th>\n",
              "      <th>1m</th>\n",
              "      <th>1ère</th>\n",
              "      <th>...</th>\n",
              "      <th>évidentes</th>\n",
              "      <th>évitant</th>\n",
              "      <th>éviter</th>\n",
              "      <th>évolution</th>\n",
              "      <th>événement</th>\n",
              "      <th>événements</th>\n",
              "      <th>êtes</th>\n",
              "      <th>être</th>\n",
              "      <th>êtres</th>\n",
              "      <th>ùmlù</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>801</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>642 rows × 2663 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e9958eb-1150-459e-b879-98bae2750f8a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e9958eb-1150-459e-b879-98bae2750f8a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e9958eb-1150-459e-b879-98bae2750f8a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the training and the test data\n",
        "X_train = df_dtm.iloc[:485,:]\n",
        "X_test = df_dtm.iloc[485:,:]"
      ],
      "metadata": {
        "id": "K1cZY8i-MV0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vcsxRWuWtIzx",
        "outputId": "0622be77-1185-4771-9d9c-107f144d4329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     05  10  11  12e  15  17  19  1la  1m  1ère  ...  évidentes  évitant  \\\n",
              "599   0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "600   0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "602   0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "603   0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "604   0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "..   ..  ..  ..  ...  ..  ..  ..  ...  ..   ...  ...        ...      ...   \n",
              "798   0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "799   0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "800   0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "801   0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "802   0   0   0    0   0   0   0    0   0     0  ...          0        0   \n",
              "\n",
              "     éviter  évolution  événement  événements  êtes  être  êtres  ùmlù  \n",
              "599       0          0          0           0     0     0      0     0  \n",
              "600       0          0          0           0     0     0      0     0  \n",
              "602       0          0          0           0     0     0      0     0  \n",
              "603       0          0          0           0     0     0      0     0  \n",
              "604       0          0          0           0     0     2      0     0  \n",
              "..      ...        ...        ...         ...   ...   ...    ...   ...  \n",
              "798       0          0          0           0     0     1      0     0  \n",
              "799       0          0          0           0     0     0      0     0  \n",
              "800       0          0          0           0     0     0      0     0  \n",
              "801       0          0          0           0     0     0      0     0  \n",
              "802       0          0          0           0     0     0      0     0  \n",
              "\n",
              "[157 rows x 2663 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-567ea78b-b8fc-4414-ad1c-ff4e87a95f92\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>05</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12e</th>\n",
              "      <th>15</th>\n",
              "      <th>17</th>\n",
              "      <th>19</th>\n",
              "      <th>1la</th>\n",
              "      <th>1m</th>\n",
              "      <th>1ère</th>\n",
              "      <th>...</th>\n",
              "      <th>évidentes</th>\n",
              "      <th>évitant</th>\n",
              "      <th>éviter</th>\n",
              "      <th>évolution</th>\n",
              "      <th>événement</th>\n",
              "      <th>événements</th>\n",
              "      <th>êtes</th>\n",
              "      <th>être</th>\n",
              "      <th>êtres</th>\n",
              "      <th>ùmlù</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>603</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>604</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>801</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>157 rows × 2663 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-567ea78b-b8fc-4414-ad1c-ff4e87a95f92')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-567ea78b-b8fc-4414-ad1c-ff4e87a95f92 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-567ea78b-b8fc-4414-ad1c-ff4e87a95f92');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the training data\n",
        "train_vectors, test_vectors, train_labels, test_labels = train_test_split(X_train, Y_train, test_size=.2)"
      ],
      "metadata": {
        "id": "eHCSDf0rfRND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_vectors.shape)\n",
        "print(train_labels.shape)"
      ],
      "metadata": {
        "id": "VhsYC8Hegm7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b824ebaf-1792-412a-a09d-44b9acf9f658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(388, 2663)\n",
            "(388, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training"
      ],
      "metadata": {
        "id": "U-VEOVFXK2UN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fc(couche_prec, nbr_neurone):\n",
        "  w = tf.Variable(tf.truncated_normal(shape=(int(couche_prec.shape[-1]), nbr_neurone)), dtype=tf.float32)\n",
        "  b = np.zeros(shape=(nbr_neurone))\n",
        "      # Résultats somme pondérée et fonction d'activation (sigmoid)\n",
        "  result = tf.matmul(couche_prec, w) + b\n",
        "  result = tf.nn.relu(result)\n",
        "  return result"
      ],
      "metadata": {
        "id": "fZ6Lxkp0K5Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taille_batch=20\n",
        "epoch_nbr=50\n",
        "learning_rate=0.001\n",
        "\n",
        "ph_vecteurs= tf.placeholder(shape=(None, 2663), dtype=tf.float32)\n",
        "ph_labels= tf.placeholder(shape=(None, 4), dtype=tf.float32)\n",
        "\n",
        "#Layer 1 \n",
        "result1 = fc(ph_vecteurs,1024)\n",
        "\n",
        "#Layer 2\n",
        "result2 = fc(result1,256)\n",
        "\n",
        "#Layer 3 \n",
        "result3 = fc(result2,128)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Sortie\n",
        "wcs = tf.Variable(tf.truncated_normal(shape=(128, 4)), dtype=tf.float32)\n",
        "bcs = tf.Variable(np.zeros(shape=(4)), dtype=tf.float32)\n",
        "scs = tf.matmul(result3, wcs)+bcs\n",
        "scso = tf.nn.sigmoid(scs)\n",
        "\n",
        "# Définition fct loss (cross entropie) et descente de gradient (GradientDescentOptimizer)\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss(ph_labels,scs))\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(scso, 1), tf.argmax(ph_labels, 1)), dtype=tf.float32))\n",
        "\n",
        "with tf.Session() as s:\n",
        "    \n",
        "    # Initialisation des variables\n",
        "    s.run(tf.global_variables_initializer())\n",
        "\n",
        "    tab_acc_train=[]\n",
        "    tab_acc_test=[]\n",
        "    output= np.zeros((1,4))\n",
        "    \n",
        "    for id_entrainement in range(epoch_nbr):\n",
        "        print(\"ID entrainement\", id_entrainement)\n",
        "        for batch in range(0, len(train_vectors), taille_batch):\n",
        "            # lancement de l'apprentissage en passant la commande \"train\". feed_dict est l'option désignant ce qui est placé dans les placeholders\n",
        "          s.run(train, feed_dict={ ph_vecteurs: train_vectors[batch:batch+taille_batch], ph_labels: train_labels[batch:batch+taille_batch]})\n",
        "        # Prédiction du modèle sur les batchs du dataset de training\n",
        "        tab_acc=[]\n",
        "        for batch in range(0, len(train_vectors), taille_batch):\n",
        "            # lancement de la prédiction en passant la commande \"accuracy\". feed_dict est l'option désignant ce qui est placé dans les placeholders\n",
        "          acc = s.run(accuracy, feed_dict={ph_vecteurs: train_vectors[batch:batch+taille_batch], ph_labels: train_labels[batch:batch+taille_batch] })\n",
        "            \n",
        "            # création le tableau des accuracies\n",
        "          tab_acc.append(acc)\n",
        "        \n",
        "        # calcul de la moyenne des accuracies \n",
        "        print(\"accuracy train:\", np.mean(tab_acc))\n",
        "        tab_acc_train.append(1-np.mean(tab_acc))\n",
        "        \n",
        "        tab_test = []\n",
        "        acc = s.run(accuracy, feed_dict={ ph_vecteurs: test_vectors, ph_labels: test_labels})\n",
        "        tab_test.append(acc)\n",
        "        \n",
        "        print(\"accuracy test :\", np.mean(tab_test))\n",
        "        tab_acc_test.append(1 - np.mean(tab_test))\n",
        "  \n",
        "    output = s.run(scso, feed_dict={ph_vecteurs: X_test})\n",
        " \n",
        "# Tracer la courbe d'erreur\n",
        "plot.ylim(0, 1)\n",
        "plot.grid()\n",
        "plot.plot(tab_acc_train, label=\"Train error\")\n",
        "plot.plot(tab_acc_test, label=\"Test error\")\n",
        "plot.legend(loc=\"upper right\")\n",
        "plot.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Fu6jM80ZMHqI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "041b7e46-ddf1-49db-c7df-8f7411683743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID entrainement 0\n",
            "accuracy train: 0.42\n",
            "accuracy test : 0.3298969\n",
            "ID entrainement 1\n",
            "accuracy train: 0.45\n",
            "accuracy test : 0.36082473\n",
            "ID entrainement 2\n",
            "accuracy train: 0.5075\n",
            "accuracy test : 0.3814433\n",
            "ID entrainement 3\n",
            "accuracy train: 0.6375\n",
            "accuracy test : 0.4329897\n",
            "ID entrainement 4\n",
            "accuracy train: 0.695\n",
            "accuracy test : 0.44329897\n",
            "ID entrainement 5\n",
            "accuracy train: 0.72625\n",
            "accuracy test : 0.4226804\n",
            "ID entrainement 6\n",
            "accuracy train: 0.78749996\n",
            "accuracy test : 0.4742268\n",
            "ID entrainement 7\n",
            "accuracy train: 0.75625\n",
            "accuracy test : 0.44329897\n",
            "ID entrainement 8\n",
            "accuracy train: 0.82250005\n",
            "accuracy test : 0.48453608\n",
            "ID entrainement 9\n",
            "accuracy train: 0.84\n",
            "accuracy test : 0.48453608\n",
            "ID entrainement 10\n",
            "accuracy train: 0.8\n",
            "accuracy test : 0.46391752\n",
            "ID entrainement 11\n",
            "accuracy train: 0.83374995\n",
            "accuracy test : 0.46391752\n",
            "ID entrainement 12\n",
            "accuracy train: 0.8575001\n",
            "accuracy test : 0.4742268\n",
            "ID entrainement 13\n",
            "accuracy train: 0.8675\n",
            "accuracy test : 0.4742268\n",
            "ID entrainement 14\n",
            "accuracy train: 0.855\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 15\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.48453608\n",
            "ID entrainement 16\n",
            "accuracy train: 0.87250006\n",
            "accuracy test : 0.46391752\n",
            "ID entrainement 17\n",
            "accuracy train: 0.87000006\n",
            "accuracy test : 0.46391752\n",
            "ID entrainement 18\n",
            "accuracy train: 0.88\n",
            "accuracy test : 0.4742268\n",
            "ID entrainement 19\n",
            "accuracy train: 0.88250005\n",
            "accuracy test : 0.4742268\n",
            "ID entrainement 20\n",
            "accuracy train: 0.86625004\n",
            "accuracy test : 0.4742268\n",
            "ID entrainement 21\n",
            "accuracy train: 0.86375\n",
            "accuracy test : 0.46391752\n",
            "ID entrainement 22\n",
            "accuracy train: 0.86375\n",
            "accuracy test : 0.46391752\n",
            "ID entrainement 23\n",
            "accuracy train: 0.86375\n",
            "accuracy test : 0.46391752\n",
            "ID entrainement 24\n",
            "accuracy train: 0.87\n",
            "accuracy test : 0.46391752\n",
            "ID entrainement 25\n",
            "accuracy train: 0.87250006\n",
            "accuracy test : 0.46391752\n",
            "ID entrainement 26\n",
            "accuracy train: 0.87250006\n",
            "accuracy test : 0.46391752\n",
            "ID entrainement 27\n",
            "accuracy train: 0.87250006\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 28\n",
            "accuracy train: 0.87250006\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 29\n",
            "accuracy train: 0.87250006\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 30\n",
            "accuracy train: 0.87250006\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 31\n",
            "accuracy train: 0.87250006\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 32\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 33\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 34\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 35\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 36\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 37\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 38\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 39\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 40\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 41\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 42\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 43\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 44\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 45\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 46\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 47\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 48\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n",
            "ID entrainement 49\n",
            "accuracy train: 0.875\n",
            "accuracy test : 0.45360824\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output prediction"
      ],
      "metadata": {
        "id": "DkELagSu1OBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "lAW7Yyd7iyAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b7176d2-5a22-4d5c-c37d-526120e74755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.00000000e+00, 8.94673109e-01, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
              "       [1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
              "       [1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 4.28193307e-04, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.38733581e-37, 1.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 9.96277392e-01, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [3.75515898e-04, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.92890312e-09],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 4.25110782e-34],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 5.37525992e-18],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 1.57186867e-18, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.11050580e-09, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
              "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 6.71190514e-34, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.11050580e-09, 1.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [4.99283018e-35, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [6.79198861e-17, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [6.90588146e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.95815286e-36, 0.00000000e+00, 3.97093754e-06, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 2.50080780e-06, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.00000000e+00, 0.00000000e+00, 1.01575134e-23, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(output)):\n",
        "  for j in range(4):\n",
        "    if (output[i,j] > 0.5):\n",
        "      output[i,j] = 1\n",
        "    else :\n",
        "      output[i,j] = 0"
      ],
      "metadata": {
        "id": "xr1nCPpwRYVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(output,columns=['Category_1','Category_2','Category_3','Category_4'])\n",
        "df = pd.concat((df,Id),axis=1)\n",
        "df= df[['Id','Category_1','Category_2','Category_3','Category_4']]\n",
        "convert_dict = {'Id': int,\n",
        "                'Category_1': int,\n",
        "                'Category_2': int,\n",
        "                'Category_3': int,\n",
        "                'Category_4': int,\n",
        "                }\n",
        "df = df.astype(convert_dict)"
      ],
      "metadata": {
        "id": "XZZHlkoYfGw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "DhAp_IXSoTPT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "e13e2d52-b1be-4440-895d-6ca151b8fa6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Id  Category_1  Category_2  Category_3  Category_4\n",
              "0    599           1           1           0           0\n",
              "1    600           0           0           0           0\n",
              "2    602           0           1           0           0\n",
              "3    603           0           1           0           0\n",
              "4    604           0           0           1           0\n",
              "..   ...         ...         ...         ...         ...\n",
              "152  798           0           1           1           0\n",
              "153  799           0           0           0           0\n",
              "154  800           0           0           1           0\n",
              "155  801           0           1           1           0\n",
              "156  802           0           0           0           0\n",
              "\n",
              "[157 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8aac6ec7-26d1-4cc0-8007-4dada8e1171a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Category_1</th>\n",
              "      <th>Category_2</th>\n",
              "      <th>Category_3</th>\n",
              "      <th>Category_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>599</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>600</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>602</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>603</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>604</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>798</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>799</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>800</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>801</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>802</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>157 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8aac6ec7-26d1-4cc0-8007-4dada8e1171a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8aac6ec7-26d1-4cc0-8007-4dada8e1171a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8aac6ec7-26d1-4cc0-8007-4dada8e1171a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"output.csv\",index=False)"
      ],
      "metadata": {
        "id": "6eM2aFxmlQUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ],
      "metadata": {
        "id": "vaC9AK2lckNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "yTqQZ11gyp9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = pd.read_csv('/content/drive/MyDrive/Dataset/Challenge/X_test.csv',sep=';')\n",
        "X_train = pd.read_csv('/content/drive/MyDrive/Dataset/Challenge/X_train.csv',sep=';')\n",
        "Y_train = pd.read_csv('/content/drive/MyDrive/Dataset/Challenge/y_train.csv',sep=';')"
      ],
      "metadata": {
        "id": "Nks-pNpLqibh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.rename(columns={'Id ':'Id'},inplace = True)\n",
        "Id = X_test['Id']\n",
        "Y_train = Y_train.drop(['Id'],axis=1)"
      ],
      "metadata": {
        "id": "glcjv7WBsPHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data building"
      ],
      "metadata": {
        "id": "JRT8AOmcyvD3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2KxatsLqQsd"
      },
      "outputs": [],
      "source": [
        "# Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train['Caption'])\n",
        "Xcnn_train = tokenizer.texts_to_sequences(X_train['Caption'])\n",
        "Xcnn_test = tokenizer.texts_to_sequences(X_test['Caption'])\n",
        "vocab_size = len(tokenizer.word_index) + 1  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length normalization\n",
        "def max_length(list):\n",
        "  max_length = 0\n",
        "  for i in range(len(list)):\n",
        "    if (len(list[i]) > max_length ):\n",
        "      max_length = len(list[i])\n",
        "  return max_length"
      ],
      "metadata": {
        "id": "RiC7A2ZyrZK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length_train = max_length(Xcnn_train)\n",
        "print(max_length_train)\n",
        "max_length_test = max_length(Xcnn_test)\n",
        "print(max_length_test)\n",
        "max_len = max(max_length_test,max_length_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkPs5qIGkULZ",
        "outputId": "421094d5-cd3c-40e1-8b33-cb19e824418c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "169\n",
            "115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_vectors(list):\n",
        "  for i in range(len(list)):\n",
        "    diff = max_len - len(list[i])\n",
        "    for j in range(diff):\n",
        "     list[i].append(0)\n",
        "   "
      ],
      "metadata": {
        "id": "GtbcAHY0k-Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize_vectors(Xcnn_test)\n",
        "normalize_vectors(Xcnn_train)"
      ],
      "metadata": {
        "id": "T66G3xO3lIUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xcnn_train = np.array(Xcnn_train)\n",
        "Xcnn_test = np.array(Xcnn_test)\n",
        "\n",
        "Xcnn_train.shape\n",
        "Xcnn_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAEhhK3esTln",
        "outputId": "15856047-3aa5-4286-c383-89f44092fec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(157, 169)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xcnn_train = Xcnn_train.reshape((-1, 169, 1))\n",
        "Xcnn_test = Xcnn_test.reshape((-1, 169, 1))"
      ],
      "metadata": {
        "id": "ntsLW6jrr1yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_vectors, test_vectors, train_labels, test_labels = train_test_split(Xcnn_train, Y_train, test_size=.2)"
      ],
      "metadata": {
        "id": "BLwq32VQsMVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xcnn_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5uLK7RYsXYz",
        "outputId": "6060f572-5abb-4f9d-c644-16d2780ab05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(485, 169, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ],
      "metadata": {
        "id": "en8cS6Tzy4yI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolution(couche_prec, taille_noyau, nbr_noyau):\n",
        "  w = tf.Variable(tf.random.truncated_normal(shape=(taille_noyau, int(couche_prec.get_shape()[-1]), nbr_noyau)))\n",
        "  b = np.zeros(shape= (nbr_noyau))\n",
        "  \n",
        "  # Définition de l'opération de convolution sur la couche_prec et ajout biais\n",
        "  result_conv = tf.nn.conv1d(couche_prec, w, stride=1, padding='SAME')\n",
        "  result = result_conv + b\n",
        "  result = tf.nn.relu(result)\n",
        "  return result\n",
        "        \n",
        "def fc(couche_prec, nbr_neurone):\n",
        "  w = tf.Variable(tf.truncated_normal(shape=(int(couche_prec.shape[-1]), nbr_neurone)), dtype=tf.float32)\n",
        "  b = np.zeros(shape=(nbr_neurone))\n",
        "      # Résultats somme pondérée et fonction d'activation (sigmoid)\n",
        "  result = tf.matmul(couche_prec, w) + b\n",
        "  result = tf.nn.sigmoid(result)\n",
        "  return result\n",
        "\n"
      ],
      "metadata": {
        "id": "5fXF4ETfy4S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taille_batch=25\n",
        "epoch_nbr=10\n",
        "learning_rate=0.001\n",
        "\n",
        "ph_vectors =tf.placeholder(shape=(None,169,1 ), dtype=tf.float32)\n",
        "ph_labels=tf.placeholder(shape=(None, 4), dtype=tf.float32)\n",
        "\n",
        "#Layer 1 \n",
        "result1 = convolution(ph_vectors,3,16)\n",
        "\n",
        "#Layer 2\n",
        "result2 = convolution(result1,5,16)\n",
        "\n",
        "\n",
        "#Layer 3 \n",
        "result3 = convolution(result2,5,32)\n",
        "\n",
        "\n",
        "#Sortie\n",
        "wcs = tf.Variable(tf.truncated_normal(shape=(32, 4)), dtype=tf.float32)\n",
        "bcs = tf.Variable(np.zeros(shape=(4)), dtype=tf.float32)\n",
        "scs = tf.matmul(result3, wcs)+bcs\n",
        "scso = tf.nn.softmax(scs)\n",
        "\n",
        "loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=ph_labels, logits=scs)\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(scso, 1), tf.argmax(ph_labels, 1)), dtype=tf.float32))\n",
        "\n",
        "with tf.Session() as s:\n",
        "    \n",
        "    # Initialisation des variables\n",
        "    s.run(tf.global_variables_initializer())\n",
        "\n",
        "    tab_acc_train=[]\n",
        "    tab_acc_test=[]\n",
        "    \n",
        "    for id_entrainement in range(epoch_nbr):\n",
        "        print(\"ID entrainement\", id_entrainement)\n",
        "            # lancement de l'apprentissage en passant la commande \"train\". feed_dict est l'option désignant ce qui est placé dans les placeholders\n",
        "        s.run(train, feed_dict={ ph_vectors: train_vectors, ph_labels: train_labels})\n",
        "\n",
        "        # Prédiction du modèle sur les batchs du dataset de training\n",
        "        tab_acc=[]\n",
        "        for batch in range(0, len(train_vectors), taille_batch):\n",
        "            # lancement de la prédiction en passant la commande \"accuracy\". feed_dict est l'option désignant ce qui est placé dans les placeholders\n",
        "            acc=s.run(accuracy, feed_dict={ph_vectors: train_vectors[batch:batch+taille_batch], ph_labels: train_labels[batch:batch+taille_batch] })\n",
        "            \n",
        "            # création le tableau des accuracies\n",
        "            tab_acc.append(acc)\n",
        "        \n",
        "        # calcul de la moyenne des accuracies \n",
        "        print(\"accuracy train:\", np.mean(tab_acc))\n",
        "        tab_acc_train.append(1-np.mean(tab_acc))\n",
        "    \n",
        "# Tracer la courbe d'erreur\n",
        "plot.ylim(0, 1)\n",
        "plot.grid()\n",
        "plot.plot(tab_acc_train, label=\"Train error\")\n",
        "plot.plot(tab_acc_test, label=\"Test error\")\n",
        "plot.legend(loc=\"upper right\")\n",
        "plot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tYeJhi5hzLjP",
        "outputId": "4679bdd4-33cf-4348-803d-41b5bda65ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID entrainement 0\n"
          ]
        },
    {
      "cell_type": "markdown",
      "source": [
        "#The plan for fine-tuning RoBERTa with the UCC\n",
        "\n",
        "### 1. Set up\n",
        "- Install transformers and pytorch lightning and import required packages.\n",
        "- Loads UCC data and inspect it.\n",
        "\n",
        "### 2. Create a dataset\n",
        "\n",
        "- Load data into pytorch dataset \n",
        "\n",
        "### 3. Build the model\n",
        " - Create a new pytorch (lightning) model with the Hugging Face RoBERTa model and a multi-label classification head.\n",
        "\n",
        "### 4. Test model performance\n",
        "- Test model performance using the ROC AUC and same test-set used in the original paper."
      ],
      "metadata": {
        "id": "p5Iuv7q7Dtg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "5_e0-rwAd22e",
        "outputId": "5714d374-f4c1-4315-d41b-4201e79f4a10",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:37:28.402972Z",
          "iopub.execute_input": "2023-02-03T11:37:28.403474Z",
          "iopub.status.idle": "2023-02-03T11:37:29.716774Z",
          "shell.execute_reply.started": "2023-02-03T11:37:28.403390Z",
          "shell.execute_reply": "2023-02-03T11:37:29.715379Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Fri Feb  3 11:37:29 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   32C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "hXnkQSWWJ5dE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install pytorch-lightning\n"
      ],
      "metadata": {
        "id": "zh8fsBTEmlSd",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:37:29.720339Z",
          "iopub.execute_input": "2023-02-03T11:37:29.720861Z",
          "iopub.status.idle": "2023-02-03T11:37:50.828125Z",
          "shell.execute_reply.started": "2023-02-03T11:37:29.720819Z",
          "shell.execute_reply": "2023-02-03T11:37:50.826816Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-03T11:37:50.829778Z",
          "iopub.execute_input": "2023-02-03T11:37:50.830194Z",
          "iopub.status.idle": "2023-02-03T11:37:50.834920Z",
          "shell.execute_reply.started": "2023-02-03T11:37:50.830149Z",
          "shell.execute_reply": "2023-02-03T11:37:50.834048Z"
        },
        "trusted": true,
        "id": "QpJx3PcBIawa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "X_test = pd.read_csv('../input/chal-data-nlp/X_test.csv',sep=';')\n",
        "X_train = pd.read_csv('../input/chal-data-nlp/X_train.csv',sep=';')\n",
        "Y_train = pd.read_csv('../input/chal-data-nlp/y_train.csv',sep=';')\n",
        "non_labeled_data = pd.read_csv('../input/chal-data-nlp/nonlabeled_data.csv',sep=';')\n",
        "sampleSubmission = pd.read_csv('../input/chal-data-nlp/sampleSubmission.csv',sep=';')\n"
      ],
      "metadata": {
        "id": "LYHit0GicSyU",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:37:50.838747Z",
          "iopub.execute_input": "2023-02-03T11:37:50.839556Z",
          "iopub.status.idle": "2023-02-03T11:37:50.936341Z",
          "shell.execute_reply.started": "2023-02-03T11:37:50.839520Z",
          "shell.execute_reply": "2023-02-03T11:37:50.935416Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = X_train.merge(Y_train, on = 'Id')"
      ],
      "metadata": {
        "id": "_GMaDvSeoqBZ",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:37:50.937854Z",
          "iopub.execute_input": "2023-02-03T11:37:50.938514Z",
          "iopub.status.idle": "2023-02-03T11:37:50.959631Z",
          "shell.execute_reply.started": "2023-02-03T11:37:50.938478Z",
          "shell.execute_reply": "2023-02-03T11:37:50.958629Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "train_data, test_data= train_test_split(data , test_size=0.10, random_state=42)"
      ],
      "metadata": {
        "id": "MfM4nYV4pWr2",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:37:50.962078Z",
          "iopub.execute_input": "2023-02-03T11:37:50.962866Z",
          "iopub.status.idle": "2023-02-03T11:37:51.467409Z",
          "shell.execute_reply.started": "2023-02-03T11:37:50.962830Z",
          "shell.execute_reply": "2023-02-03T11:37:51.466452Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "5TSqU5BoYPct",
        "outputId": "114c5846-2c42-4713-d787-e076770fdf16",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:37:51.468728Z",
          "iopub.execute_input": "2023-02-03T11:37:51.469122Z",
          "iopub.status.idle": "2023-02-03T11:37:51.491866Z",
          "shell.execute_reply.started": "2023-02-03T11:37:51.469080Z",
          "shell.execute_reply": "2023-02-03T11:37:51.491023Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "      Id                                            Caption  category_1  \\\n39    50                                  La peur de mourir           1   \n431  527  l'après corona , quels réels changements de vi...           0   \n399  488  je n'ai que des inquiétudes modérées,compte te...           0   \n185  227  - confinement qui dure plus longtemps qu'annon...           0   \n382  466  La peur d'être contaminé et de contaminer les ...           1   \n..   ...                                                ...         ...   \n106  129                                              tfutu           0   \n270  334  Je suis une personne à risque et je pense que ...           1   \n348  427                                         Sanitaires           0   \n435  531                     Rebond après le déconfinement.           0   \n102  125             Finir ma vie seul dans un box à 85 ans           1   \n\n     category_2  category_3  category_4  \n39            0           0           0  \n431           0           1           0  \n399           0           0           1  \n185           1           1           0  \n382           1           0           0  \n..          ...         ...         ...  \n106           0           0           0  \n270           0           0           0  \n348           0           0           1  \n435           0           1           0  \n102           0           0           0  \n\n[436 rows x 6 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Caption</th>\n      <th>category_1</th>\n      <th>category_2</th>\n      <th>category_3</th>\n      <th>category_4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39</th>\n      <td>50</td>\n      <td>La peur de mourir</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>431</th>\n      <td>527</td>\n      <td>l'après corona , quels réels changements de vi...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>488</td>\n      <td>je n'ai que des inquiétudes modérées,compte te...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>227</td>\n      <td>- confinement qui dure plus longtemps qu'annon...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>382</th>\n      <td>466</td>\n      <td>La peur d'être contaminé et de contaminer les ...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>129</td>\n      <td>tfutu</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>270</th>\n      <td>334</td>\n      <td>Je suis une personne à risque et je pense que ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>348</th>\n      <td>427</td>\n      <td>Sanitaires</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>435</th>\n      <td>531</td>\n      <td>Rebond après le déconfinement.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>125</td>\n      <td>Finir ma vie seul dans un box à 85 ans</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>436 rows × 6 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# inspect data"
      ],
      "metadata": {
        "id": "GDdLgBECpnJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "attributes = ['category_1',\t'category_2','category_3',\t'category_4']\n",
        "\n",
        "for attribute in attributes:\n",
        "  X_test[attribute] = np.zeros((X_test.shape[0],1))\n",
        "\n",
        "train_data[attributes].sum().plot.bar()"
      ],
      "metadata": {
        "id": "aN6M-KaApoRo",
        "outputId": "a9786a5d-ea5f-4fc2-9ce5-10f3c21aa737",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:37:51.493844Z",
          "iopub.execute_input": "2023-02-03T11:37:51.494754Z",
          "iopub.status.idle": "2023-02-03T11:37:51.720472Z",
          "shell.execute_reply.started": "2023-02-03T11:37:51.494719Z",
          "shell.execute_reply": "2023-02-03T11:37:51.719344Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<AxesSubplot:>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "model_name = 'camembert-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "token_counts = []\n",
        "\n",
        "for _, row in X_train.iterrows():\n",
        "  token_count = len(tokenizer.encode(\n",
        "    row[\"Caption\"], \n",
        "    max_length=1000, \n",
        "    truncation=True\n",
        "  ))\n",
        "  token_counts.append(token_count)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-03T11:37:51.723631Z",
          "iopub.execute_input": "2023-02-03T11:37:51.723897Z",
          "iopub.status.idle": "2023-02-03T11:38:08.212531Z",
          "shell.execute_reply.started": "2023-02-03T11:37:51.723872Z",
          "shell.execute_reply": "2023-02-03T11:38:08.211547Z"
        },
        "trusted": true,
        "id": "rUIPDD7AH_FJ",
        "outputId": "7918e781-e1aa-4d8f-b46c-a239cd738db2",
        "colab": {
          "referenced_widgets": [
            "154555f3ac734fd0b379152630583965",
            "a50c4809ce074d76a7ddb2fc50b07328",
            "0500ea54213c4efdbeec4f00dc9c61fe"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/508 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "154555f3ac734fd0b379152630583965"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a50c4809ce074d76a7ddb2fc50b07328"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/1.33M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0500ea54213c4efdbeec4f00dc9c61fe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.histplot(token_counts)\n",
        "plt.xlim([0, 1000]);"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:08.216807Z",
          "iopub.execute_input": "2023-02-03T11:38:08.217291Z",
          "iopub.status.idle": "2023-02-03T11:38:08.638550Z",
          "shell.execute_reply.started": "2023-02-03T11:38:08.217261Z",
          "shell.execute_reply": "2023-02-03T11:38:08.637667Z"
        },
        "trusted": true,
        "id": "UHBOmu8zH_FL",
        "outputId": "181b2339-04b7-438d-ad18-ff18f6b1ef5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 720x720 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "ECq7VkvoqR4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "OHYq_l9vqSs_",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:08.639850Z",
          "iopub.execute_input": "2023-02-03T11:38:08.640224Z",
          "iopub.status.idle": "2023-02-03T11:38:08.645706Z",
          "shell.execute_reply.started": "2023-02-03T11:38:08.640186Z",
          "shell.execute_reply": "2023-02-03T11:38:08.644621Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Cov_Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, data: pd.DataFrame , tokenizer, attributes, max_token_len: int = 128, sample = 485):\n",
        "    self.data = data\n",
        "    self.tokenizer = tokenizer\n",
        "    self.attributes = attributes\n",
        "    self.max_token_len = max_token_len\n",
        "    self.sample = sample\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    item = self.data.iloc[index]\n",
        "    caption = str(item.Caption)\n",
        "    attributes = torch.FloatTensor(item[self.attributes])\n",
        "    tokens = self.tokenizer.encode_plus(caption,\n",
        "                                        add_special_tokens=True,\n",
        "                                        return_tensors='pt',\n",
        "                                        truncation=True,\n",
        "                                        padding='max_length',\n",
        "                                        max_length=self.max_token_len,\n",
        "                                        return_attention_mask = True)\n",
        "    return {'input_ids': tokens.input_ids.flatten(), 'attention_mask': tokens.attention_mask.flatten(), 'labels': attributes}\n"
      ],
      "metadata": {
        "id": "WuDSi08sqVYe",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:08.647786Z",
          "iopub.execute_input": "2023-02-03T11:38:08.648207Z",
          "iopub.status.idle": "2023-02-03T11:38:08.657966Z",
          "shell.execute_reply.started": "2023-02-03T11:38:08.648172Z",
          "shell.execute_reply": "2023-02-03T11:38:08.657035Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cov_ds = Cov_Dataset(train_data, tokenizer, attributes=attributes)\n",
        "cov_ds_val = Cov_Dataset(test_data, tokenizer, attributes=attributes, sample=None)\n",
        "cov_ds_test = Cov_Dataset(X_test,tokenizer, attributes = attributes, sample = None)"
      ],
      "metadata": {
        "id": "N5TfbQjBrshN",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:08.659341Z",
          "iopub.execute_input": "2023-02-03T11:38:08.660436Z",
          "iopub.status.idle": "2023-02-03T11:38:08.668922Z",
          "shell.execute_reply.started": "2023-02-03T11:38:08.660401Z",
          "shell.execute_reply": "2023-02-03T11:38:08.668074Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cov_ds.__getitem__(0)['labels'].shape, cov_ds.__getitem__(0)['input_ids'].shape, cov_ds.__getitem__(0)['attention_mask'].shape"
      ],
      "metadata": {
        "id": "AxG1q2R5sKe9",
        "outputId": "84189556-59cb-484e-984f-8be241c3e456",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:08.670476Z",
          "iopub.execute_input": "2023-02-03T11:38:08.671013Z",
          "iopub.status.idle": "2023-02-03T11:38:08.683221Z",
          "shell.execute_reply.started": "2023-02-03T11:38:08.670952Z",
          "shell.execute_reply": "2023-02-03T11:38:08.682214Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(torch.Size([4]), torch.Size([128]), torch.Size([128]))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cov_ds.__getitem__(3)"
      ],
      "metadata": {
        "id": "E3piF8-ScLkB",
        "outputId": "bdf9b6d5-36d2-4b23-b4c7-1eec36ec4ae4",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:08.684723Z",
          "iopub.execute_input": "2023-02-03T11:38:08.685088Z",
          "iopub.status.idle": "2023-02-03T11:38:08.696430Z",
          "shell.execute_reply.started": "2023-02-03T11:38:08.685053Z",
          "shell.execute_reply": "2023-02-03T11:38:08.695438Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'input_ids': tensor([    5,    67, 12076,  3546,    31,  3246,    40,   892,    46,    11,\n         13758,  2162,    67,   217,     8,   497,    36,  4103,    67,    13,\n          1133,   570, 19754,   422,    16,   210,   143,  1921,     6,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]),\n 'labels': tensor([0., 1., 1., 0.])}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(cov_ds_test)"
      ],
      "metadata": {
        "id": "vdnNmd2ScreK",
        "outputId": "1be226f8-efdc-46f6-ad46-9645a8aa7529",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:08.697790Z",
          "iopub.execute_input": "2023-02-03T11:38:08.698185Z",
          "iopub.status.idle": "2023-02-03T11:38:08.706366Z",
          "shell.execute_reply.started": "2023-02-03T11:38:08.698151Z",
          "shell.execute_reply": "2023-02-03T11:38:08.705109Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "157"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data module"
      ],
      "metadata": {
        "id": "gUr-j36ctWH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "fdPf54AatXaX",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:08.708069Z",
          "iopub.execute_input": "2023-02-03T11:38:08.708451Z",
          "iopub.status.idle": "2023-02-03T11:38:10.889959Z",
          "shell.execute_reply.started": "2023-02-03T11:38:08.708396Z",
          "shell.execute_reply": "2023-02-03T11:38:10.888952Z"
        },
        "trusted": true,
        "outputId": "8a79bdec-fcbd-482f-9e71-9e58088cae40"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Cov_Data_Module(pl.LightningDataModule):\n",
        "\n",
        "  def __init__(self, train_data : pd.DataFrame, val_data: pd.DataFrame, attributes, batch_size: int =16, max_token_length: int = 128,  model_name='camembert-base'):\n",
        "    super().__init__()\n",
        "    self.train_data = train_data\n",
        "    self.val_data = val_data\n",
        "    self.attributes = attributes\n",
        "    self.batch_size = batch_size\n",
        "    self.max_token_length = max_token_length\n",
        "    self.model_name = model_name\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "  def setup(self, stage = None):\n",
        "    if stage in (None, \"fit\"):\n",
        "      self.train_dataset = Cov_Dataset(self.train_data, attributes=self.attributes, tokenizer=self.tokenizer)\n",
        "      self.val_dataset = Cov_Dataset(self.val_data, attributes=self.attributes, tokenizer=self.tokenizer, sample=None)\n",
        "    if stage == 'predict':\n",
        "      self.val_dataset = Cov_Dataset(self.val_data, attributes=self.attributes, tokenizer=self.tokenizer, sample=None)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.train_dataset, batch_size = self.batch_size, num_workers=1, shuffle=True)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.val_dataset, batch_size = self.batch_size, num_workers=1, shuffle=False)\n",
        "\n",
        "  def predict_dataloader(self):\n",
        "    return DataLoader(self.val_dataset, batch_size = 1, num_workers=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "k7PxkuevtkpS",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:10.891444Z",
          "iopub.execute_input": "2023-02-03T11:38:10.892333Z",
          "iopub.status.idle": "2023-02-03T11:38:10.903073Z",
          "shell.execute_reply.started": "2023-02-03T11:38:10.892295Z",
          "shell.execute_reply": "2023-02-03T11:38:10.902048Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cov_data_module = Cov_Data_Module(train_data, test_data, attributes=attributes)"
      ],
      "metadata": {
        "id": "weSlOGEsvB0j",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:10.904713Z",
          "iopub.execute_input": "2023-02-03T11:38:10.905332Z",
          "iopub.status.idle": "2023-02-03T11:38:20.073758Z",
          "shell.execute_reply.started": "2023-02-03T11:38:10.905296Z",
          "shell.execute_reply": "2023-02-03T11:38:20.072766Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cov_data_module = Cov_Data_Module(train_data, test_data, attributes=attributes)"
      ],
      "metadata": {
        "id": "48Xgf5FiZg8q",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:20.075050Z",
          "iopub.execute_input": "2023-02-03T11:38:20.075406Z",
          "iopub.status.idle": "2023-02-03T11:38:29.258541Z",
          "shell.execute_reply.started": "2023-02-03T11:38:20.075373Z",
          "shell.execute_reply": "2023-02-03T11:38:29.257548Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cov_data_module.setup()"
      ],
      "metadata": {
        "id": "oMSwVVq_vJPQ",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:29.263651Z",
          "iopub.execute_input": "2023-02-03T11:38:29.266270Z",
          "iopub.status.idle": "2023-02-03T11:38:29.272281Z",
          "shell.execute_reply.started": "2023-02-03T11:38:29.266230Z",
          "shell.execute_reply": "2023-02-03T11:38:29.271291Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cov_data_module.train_dataloader()"
      ],
      "metadata": {
        "id": "unF1JP_hvMnq",
        "outputId": "9af95e7e-96bb-423b-99b8-56558bc9964a",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:29.277199Z",
          "iopub.execute_input": "2023-02-03T11:38:29.280106Z",
          "iopub.status.idle": "2023-02-03T11:38:29.290363Z",
          "shell.execute_reply.started": "2023-02-03T11:38:29.280058Z",
          "shell.execute_reply": "2023-02-03T11:38:29.289457Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 22,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<torch.utils.data.dataloader.DataLoader at 0x7f7d1d1e8cd0>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(cov_data_module.train_dataloader())"
      ],
      "metadata": {
        "id": "kCBaHGBsvQaw",
        "outputId": "70d2a9aa-7744-4699-e5d3-b7bbc20729f4",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:29.294632Z",
          "iopub.execute_input": "2023-02-03T11:38:29.295242Z",
          "iopub.status.idle": "2023-02-03T11:38:29.304745Z",
          "shell.execute_reply.started": "2023-02-03T11:38:29.295208Z",
          "shell.execute_reply": "2023-02-03T11:38:29.303781Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "28"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "as2bbkWmwFO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AdamW, get_cosine_schedule_with_warmup\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torchmetrics.functional.classification import auroc\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "pJ7T-xtnwGpw",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:29.307029Z",
          "iopub.execute_input": "2023-02-03T11:38:29.307826Z",
          "iopub.status.idle": "2023-02-03T11:38:32.956725Z",
          "shell.execute_reply.started": "2023-02-03T11:38:29.307733Z",
          "shell.execute_reply": "2023-02-03T11:38:32.955763Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Cov_Caption_Classifier(pl.LightningModule):\n",
        "\n",
        "  def __init__(self, config: dict):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "    self.pretrained_model = AutoModel.from_pretrained(config['model_name'], return_dict = True)\n",
        "    self.hidden = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.pretrained_model.config.hidden_size)\n",
        "    self.classifier = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.config['n_labels'])\n",
        "    torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
        "    self.loss_func = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "    self.dropout = nn.Dropout()\n",
        "    \n",
        "  def forward(self, input_ids, attention_mask, labels=None):\n",
        "    # roberta layer\n",
        "    output = self.pretrained_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    pooled_output = torch.mean(output.last_hidden_state, 1)\n",
        "    # final logits\n",
        "    pooled_output = self.dropout(pooled_output)\n",
        "    pooled_output = self.hidden(pooled_output)\n",
        "    pooled_output = F.relu(pooled_output)\n",
        "    pooled_output = self.dropout(pooled_output)\n",
        "    logits = self.classifier(pooled_output)\n",
        "    # calculate loss\n",
        "    loss = 0\n",
        "    if labels is not None:\n",
        "      loss = self.loss_func(logits.view(-1, self.config['n_labels']), labels.view(-1, self.config['n_labels']))\n",
        "    return loss, logits\n",
        "\n",
        "  def training_step(self, batch, batch_index):\n",
        "    loss, outputs = self(**batch)\n",
        "    self.log(\"train loss \", loss, prog_bar = True, logger=True)\n",
        "    return {\"loss\":loss, \"predictions\":outputs, \"labels\": batch[\"labels\"]}\n",
        "\n",
        "  def validation_step(self, batch, batch_index):\n",
        "    loss, outputs = self(**batch)\n",
        "    self.log(\"validation loss \", loss, prog_bar = True, logger=True)\n",
        "    return {\"val_loss\": loss, \"predictions\":outputs, \"labels\": batch[\"labels\"]}\n",
        "\n",
        "  def predict_step(self, batch, batch_index):\n",
        "    loss, outputs = self(**batch)\n",
        "    return outputs\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = AdamW(self.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])\n",
        "    total_steps = self.config['train_size']/self.config['batch_size']\n",
        "    warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
        "    warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
        "    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "    return [optimizer],[scheduler]\n",
        "  # def validation_epoch_end(self, outputs):\n",
        "  #   losses = []\n",
        "  #   for output in outputs:\n",
        "  #     loss = output['val_loss'].detach().cpu()\n",
        "  #     losses.append(loss)\n",
        "  #   avg_loss = torch.mean(torch.stack(losses))\n",
        "  #   self.log(\"avg_val_loss\", avg_loss)\n",
        "    "
      ],
      "metadata": {
        "id": "xeLW6BYUwUTu",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:32.958097Z",
          "iopub.execute_input": "2023-02-03T11:38:32.958436Z",
          "iopub.status.idle": "2023-02-03T11:38:32.972946Z",
          "shell.execute_reply.started": "2023-02-03T11:38:32.958400Z",
          "shell.execute_reply": "2023-02-03T11:38:32.971946Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'model_name': 'camembert-base',\n",
        "    'n_labels': len(attributes),\n",
        "    'batch_size': 20,\n",
        "    'lr': 1.5e-5,\n",
        "    'warmup': 0.2, \n",
        "    'train_size': len(cov_data_module.train_dataloader()),\n",
        "    'weight_decay': 0.001,\n",
        "    'n_epochs': 30\n",
        "}\n",
        "\n",
        "model = Cov_Caption_Classifier(config)"
      ],
      "metadata": {
        "id": "ioZPU0CCziRN",
        "outputId": "82de61a4-9938-44a2-eb98-fa29876b72b2",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:38:32.974586Z",
          "iopub.execute_input": "2023-02-03T11:38:32.975239Z",
          "iopub.status.idle": "2023-02-03T11:39:17.576126Z",
          "shell.execute_reply.started": "2023-02-03T11:38:32.975198Z",
          "shell.execute_reply": "2023-02-03T11:39:17.575166Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "9d49329e127f460fad4ee92a25029551"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/424M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d49329e127f460fad4ee92a25029551"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx=0\n",
        "input_ids = cov_ds.__getitem__(idx)['input_ids']\n",
        "attention_mask = cov_ds.__getitem__(idx)['attention_mask']\n",
        "labels = cov_ds.__getitem__(idx)['labels']\n",
        "model.cpu()\n",
        "loss, output = model(input_ids.unsqueeze(dim=0), attention_mask.unsqueeze(dim=0), labels.unsqueeze(dim=0))\n",
        "print(labels.shape, output.shape, output)"
      ],
      "metadata": {
        "id": "o0KK_ffoz_dx",
        "outputId": "59151c29-3eb4-4eff-840c-ef6b2dfdf82a",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:39:17.577948Z",
          "iopub.execute_input": "2023-02-03T11:39:17.578359Z",
          "iopub.status.idle": "2023-02-03T11:39:18.021042Z",
          "shell.execute_reply.started": "2023-02-03T11:39:17.578322Z",
          "shell.execute_reply": "2023-02-03T11:39:18.019166Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "torch.Size([4]) torch.Size([1, 4]) tensor([[ 0.0964, -0.1094,  0.4889, -0.2085]], grad_fn=<AddmmBackward0>)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # train model"
      ],
      "metadata": {
        "id": "pOeSkQmg06M0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# datamodule\n",
        "cov_data_module = Cov_Data_Module(train_data, test_data, attributes=attributes, batch_size=config['batch_size'])\n",
        "cov_data_module.setup()\n",
        "\n",
        "# model\n",
        "model = Cov_Caption_Classifier(config)\n",
        "\n",
        "# trainer and fit\n",
        "trainer = pl.Trainer(max_epochs=config['n_epochs'], gpus=1, num_sanity_val_steps=20)\n",
        "trainer.fit(model, cov_data_module)\n"
      ],
      "metadata": {
        "id": "SYNN5lgq07sd",
        "outputId": "28bcf6d9-81fe-4c97-db79-f5c94386c7e4",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:39:18.027113Z",
          "iopub.execute_input": "2023-02-03T11:39:18.027416Z",
          "iopub.status.idle": "2023-02-03T11:44:55.103282Z",
          "shell.execute_reply.started": "2023-02-03T11:39:18.027388Z",
          "shell.execute_reply": "2023-02-03T11:44:55.102167Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "",
            "5d151d4507804024b0a8b59a6c70b08e"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:468: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1604: PossibleUserWarning: The number of training batches (22) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n  category=PossibleUserWarning,\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Training: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d151d4507804024b0a8b59a6c70b08e"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /lightning_logs"
      ],
      "metadata": {
        "id": "nt7e_jxh1O1_",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:44:55.104865Z",
          "iopub.execute_input": "2023-02-03T11:44:55.105259Z",
          "iopub.status.idle": "2023-02-03T11:45:01.254461Z",
          "shell.execute_reply.started": "2023-02-03T11:44:55.105215Z",
          "shell.execute_reply": "2023-02-03T11:45:01.253345Z"
        },
        "trusted": true,
        "outputId": "859462b8-6f31-4277-8b3b-3625c11dd6a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n      <iframe id=\"tensorboard-frame-9774dea2a5522274\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-9774dea2a5522274\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_checkpoint(\"/content/last-checkpoint.ckpt\")\n"
      ],
      "metadata": {
        "id": "8avvIsl-nXsv",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:45:01.256573Z",
          "iopub.execute_input": "2023-02-03T11:45:01.257002Z",
          "iopub.status.idle": "2023-02-03T11:45:05.524785Z",
          "shell.execute_reply.started": "2023-02-03T11:45:01.256944Z",
          "shell.execute_reply": "2023-02-03T11:45:05.523433Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_result = []\n",
        "for caption in X_test['Caption']:\n",
        "  encoding = tokenizer.encode_plus(caption,\n",
        "                                          add_special_tokens=True,\n",
        "                                          return_tensors='pt',\n",
        "                                          truncation=True,\n",
        "                                          padding='max_length',\n",
        "                                          max_length=128,\n",
        "                                          return_attention_mask = True)\n",
        "  _, test_prediction = model(encoding[\"input_ids\"], encoding[\"attention_mask\"])\n",
        "  predictions_result.append(test_prediction.detach().cpu().numpy())\n",
        "\n"
      ],
      "metadata": {
        "id": "1z7044YGqS5e",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:45:05.531079Z",
          "iopub.execute_input": "2023-02-03T11:45:05.536016Z",
          "iopub.status.idle": "2023-02-03T11:45:51.634951Z",
          "shell.execute_reply.started": "2023-02-03T11:45:05.535941Z",
          "shell.execute_reply": "2023-02-03T11:45:51.633924Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_result =np.array(predictions_result).reshape(-1,4)\n"
      ],
      "metadata": {
        "id": "1BdHatiDDDnZ",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:45:51.636700Z",
          "iopub.execute_input": "2023-02-03T11:45:51.638252Z",
          "iopub.status.idle": "2023-02-03T11:45:51.643919Z",
          "shell.execute_reply.started": "2023-02-03T11:45:51.638213Z",
          "shell.execute_reply": "2023-02-03T11:45:51.642917Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_result"
      ],
      "metadata": {
        "id": "SQKKnB-RVZfS",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:45:51.645531Z",
          "iopub.execute_input": "2023-02-03T11:45:51.645891Z",
          "iopub.status.idle": "2023-02-03T11:45:51.664929Z",
          "shell.execute_reply.started": "2023-02-03T11:45:51.645857Z",
          "shell.execute_reply": "2023-02-03T11:45:51.664000Z"
        },
        "trusted": true,
        "outputId": "9b5323d6-9b36-4ef4-919d-d34e5502b75c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 33,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[-1.9367455 , -1.5800409 ,  1.9361316 , -2.1244395 ],\n       [-2.5171173 , -1.9521564 ,  2.5854533 , -3.1147501 ],\n       [-0.12778322, -1.0304463 , -0.8645155 , -1.3749416 ],\n       [-1.135506  ,  1.506468  , -1.7880824 , -1.3785897 ],\n       [-1.8420869 , -1.4417638 ,  0.59540534, -0.65347356],\n       [ 0.5311779 ,  1.2517786 , -2.1525629 , -2.4836428 ],\n       [-1.662412  , -1.9752883 ,  2.0811849 , -2.1876605 ],\n       [-1.973308  , -1.2415378 ,  1.8477647 , -1.7227176 ],\n       [-0.6041497 , -1.7904302 ,  0.72252905, -1.8824683 ],\n       [ 0.7891544 , -1.557868  , -1.3927329 , -1.5377824 ],\n       [ 0.41863933, -1.3973169 , -1.5433958 , -0.05960833],\n       [-1.7397406 , -1.6108607 ,  1.6499    , -1.6700907 ],\n       [ 1.2832108 , -0.95786685, -1.8385352 , -1.3024275 ],\n       [ 1.0543423 , -1.3791559 , -1.6406375 , -1.1128678 ],\n       [-1.6328325 , -1.7043896 ,  1.7676184 , -2.0604932 ],\n       [ 0.9397128 , -1.0860363 , -1.7771207 , -1.8977245 ],\n       [-2.0186255 ,  0.4828853 ,  0.6551064 , -1.9463991 ],\n       [-1.9340729 , -2.0126724 ,  2.233004  , -2.0093307 ],\n       [ 0.6536895 ,  0.39462665, -2.044784  , -1.872824  ],\n       [ 0.10684764, -1.5951906 , -0.42319164, -1.5697808 ],\n       [-1.0062082 , -1.9345613 , -1.108558  , -0.18877918],\n       [-1.9769232 , -1.5249844 ,  2.4741755 , -1.912116  ],\n       [-2.417761  , -2.1381052 ,  2.203685  , -2.4755414 ],\n       [ 1.0670081 , -1.1649312 , -1.6621587 , -1.4967418 ],\n       [ 0.6909387 ,  1.3700333 , -2.0694158 , -1.8472463 ],\n       [-2.1330464 , -1.8712363 ,  2.239169  , -2.6434631 ],\n       [-1.755065  , -2.3796148 ,  2.406335  , -2.0793273 ],\n       [-0.7597374 , -1.1066837 ,  0.67667556, -2.3525484 ],\n       [-2.5578716 , -1.5338482 ,  2.5873506 , -2.1573632 ],\n       [ 0.7162564 , -1.0872828 , -1.8781856 , -1.3445705 ],\n       [-2.737231  ,  0.18875931,  1.4809871 , -2.3902366 ],\n       [-2.6799045 , -2.2968786 ,  2.4034424 , -2.3131292 ],\n       [-1.4146417 , -1.4130791 ,  1.4640607 , -2.0870757 ],\n       [-1.9822533 , -0.78208196,  1.6040723 , -2.0024319 ],\n       [ 0.78043306, -1.2790278 , -2.4216464 , -1.7376416 ],\n       [-0.985477  , -1.059268  , -1.5558083 ,  0.46860486],\n       [ 0.46109393, -0.87935805, -0.61476094, -2.1358159 ],\n       [ 1.1891184 , -0.7602985 , -1.6529008 , -1.3171161 ],\n       [-1.5310999 , -2.2112837 ,  1.0780337 , -2.8253753 ],\n       [-2.2609825 , -2.0226865 ,  1.961285  , -2.2596538 ],\n       [ 1.4034187 , -1.5125355 , -1.7168721 , -1.8507657 ],\n       [ 0.9100564 , -1.1763216 , -1.0802739 , -1.7120339 ],\n       [ 1.1813284 , -0.932502  , -1.777106  , -1.2664782 ],\n       [ 0.3463416 , -0.6167047 , -0.21730228, -2.272925  ],\n       [ 0.10107994, -1.4474534 , -0.6129712 , -1.2881806 ],\n       [-1.8658208 , -1.1587889 ,  2.1666102 , -2.496319  ],\n       [ 0.6690345 , -0.94747436, -1.8934612 , -1.4817609 ],\n       [-3.1433523 , -2.0012655 ,  3.3945904 , -3.2305949 ],\n       [-1.4337188 , -0.4678009 ,  1.6092768 , -2.510607  ],\n       [-1.5898747 , -1.5958064 ,  2.6529014 , -2.2052758 ],\n       [ 0.7920828 , -1.739088  , -1.3277291 , -1.5255679 ],\n       [-1.7696495 , -1.9628997 ,  2.7163792 , -2.8550706 ],\n       [ 0.87099874, -1.1796716 , -1.1120641 , -1.10135   ],\n       [-0.7786147 , -0.22144066, -0.9431386 , -0.10356294],\n       [ 0.8234792 , -1.1557707 , -1.5801128 , -1.6546024 ],\n       [ 1.0275952 , -1.2921975 , -1.499748  , -1.0718474 ],\n       [-1.978349  ,  1.2204852 , -0.9732279 , -1.3605175 ],\n       [ 0.19350015,  0.12275957, -2.5404584 , -1.9207972 ],\n       [-2.249078  , -1.89516   ,  2.5594275 , -2.9999793 ],\n       [-2.520834  , -1.6211464 ,  1.9386301 , -2.667187  ],\n       [ 0.7204657 ,  0.47116742, -1.4552848 , -2.037782  ],\n       [-2.1099787 , -1.4486045 ,  1.3840276 , -2.1866298 ],\n       [-1.3411502 , -1.4516466 , -1.1512412 ,  0.42191386],\n       [ 0.79050267, -1.5383302 , -1.3948469 , -1.827669  ],\n       [-2.2883575 , -1.105856  ,  2.3380919 , -3.022702  ],\n       [-1.7342986 , -1.6296211 ,  1.8968264 , -2.2810998 ],\n       [-1.5672042 ,  1.0043955 ,  0.35597953, -2.8539016 ],\n       [-2.215896  , -1.2029114 ,  2.405514  , -2.5064468 ],\n       [-2.4813292 ,  0.6259646 ,  0.43763292, -2.7937293 ],\n       [ 0.12372461,  1.170444  , -2.235535  , -2.2339933 ],\n       [-1.1402535 ,  1.8106049 , -1.9174811 , -1.9258631 ],\n       [ 0.5157126 ,  0.60787016, -2.578183  , -2.0906358 ],\n       [ 0.14815196,  1.750279  , -1.873664  , -1.7564058 ],\n       [-0.9633959 , -1.353812  , -1.2898221 ,  0.35110584],\n       [-1.4232998 , -1.6958325 , -0.9396274 ,  0.43434185],\n       [ 0.67192656, -1.3430736 , -0.9840296 , -1.7748848 ],\n       [-2.1098588 , -1.2484411 ,  2.2119944 , -2.903433  ],\n       [-1.4230005 ,  1.9863135 , -0.9086392 , -2.4321775 ],\n       [-0.2871667 ,  1.6648928 , -1.7246722 , -2.2344851 ],\n       [-0.2564344 ,  1.0218829 , -1.5894036 , -2.4950867 ],\n       [-2.1321287 , -1.8745631 ,  1.519579  , -1.8086578 ],\n       [-0.74921274,  1.5734949 , -1.51446   , -1.5176262 ],\n       [-1.8019649 , -2.0981996 ,  1.2859528 , -2.6292226 ],\n       [-1.3579865 ,  2.214798  , -1.0441053 , -2.3486862 ],\n       [ 0.8374099 ,  0.30415455, -2.3717031 , -1.7792596 ],\n       [-1.598392  , -1.8002448 ,  2.0913424 , -2.443433  ],\n       [-1.4512562 , -0.8487133 ,  2.131456  , -1.8571968 ],\n       [-2.1185365 , -1.267965  ,  1.8495727 , -2.2578766 ],\n       [-1.7510536 , -1.6713916 ,  1.2952067 , -0.95537925],\n       [ 0.7300766 , -0.90121126, -1.3534372 , -1.6016119 ],\n       [-2.6550517 ,  0.93979824,  1.5924695 , -2.7983375 ],\n       [-1.5272548 ,  1.6473943 , -0.9870269 , -1.9060031 ],\n       [ 1.2887236 , -0.7739061 , -1.9587939 , -1.624598  ],\n       [-1.0081822 , -1.4839565 ,  0.07101556, -0.7554728 ],\n       [-1.3567712 ,  1.7091435 , -0.55878204, -1.7595303 ],\n       [-1.8773578 ,  0.65567094,  1.1951067 , -1.9326255 ],\n       [ 1.0098021 , -1.1592312 , -1.6886394 , -1.3845732 ],\n       [-1.7628877 , -1.6231428 ,  1.8846142 , -2.5324411 ],\n       [-2.3150296 , -1.9628578 ,  2.1893137 , -2.0144756 ],\n       [-1.5954574 ,  1.540491  , -0.63178676, -2.3558238 ],\n       [ 0.9144194 , -0.18107995, -1.5563406 , -1.6080459 ],\n       [ 1.1620849 , -1.4594998 , -1.9777341 , -1.633178  ],\n       [ 1.2369133 , -1.3315055 , -2.230037  , -1.7122153 ],\n       [-1.9670937 ,  0.6692819 ,  1.3977643 , -2.5423918 ],\n       [-1.2350756 , -1.4463611 , -0.59139574, -0.02200215],\n       [-2.5790908 , -1.4873807 ,  2.2991047 , -2.0991554 ],\n       [-2.199885  , -1.1689605 ,  2.0233846 , -2.6047254 ],\n       [-1.6966699 ,  1.2556772 ,  1.2567477 , -1.9063321 ],\n       [-2.3826456 , -1.6362097 ,  3.006537  , -2.8403478 ],\n       [-0.94692564, -1.7898358 ,  0.99024105, -2.4853318 ],\n       [-1.7467215 , -1.8144486 ,  2.1700697 , -2.4642904 ],\n       [ 0.81898606, -1.0511395 , -1.4665484 , -1.0168535 ],\n       [-2.3770916 , -1.1068883 ,  2.1910584 , -2.6659474 ],\n       [-1.9230913 , -1.4670497 ,  1.4067352 , -1.9106368 ],\n       [-1.9790858 , -1.567823  ,  2.589437  , -3.1730275 ],\n       [-1.9051082 , -0.726371  ,  1.349653  , -1.2988696 ],\n       [-2.7618046 , -1.1234614 ,  1.8213376 , -2.3163264 ],\n       [-2.2867382 , -0.9350141 ,  2.1842666 , -3.0672965 ],\n       [-1.7268026 ,  1.6124717 ,  0.11265772, -2.432794  ],\n       [ 0.6018218 ,  0.31640166, -2.002045  , -2.0303495 ],\n       [-2.3557305 , -1.8140247 ,  2.0912104 , -3.3763306 ],\n       [-2.0929606 , -1.9281507 ,  2.5968354 , -2.8351166 ],\n       [-0.79544646, -1.1810602 , -1.0327736 ,  0.2615565 ],\n       [ 0.4772521 , -1.1146737 , -1.4335868 , -0.8485138 ],\n       [-2.0493183 , -0.79852223,  0.92317647, -1.2884365 ],\n       [-2.955689  , -1.7213777 ,  1.8904955 , -1.8322614 ],\n       [-0.73464805,  1.576513  , -1.4623158 , -1.6566064 ],\n       [-1.693051  , -1.4412245 ,  0.29284742, -0.31308436],\n       [-2.1585486 , -1.4673213 ,  2.0759623 , -2.7083204 ],\n       [-1.1737856 ,  1.8782561 , -0.93215257, -2.025811  ],\n       [ 0.7788368 ,  0.2934159 , -2.1734965 , -1.6422577 ],\n       [-1.1158044 ,  1.5495307 , -0.95638174, -2.6974258 ],\n       [-0.73291725,  0.93738335, -1.6751677 , -1.7927283 ],\n       [-1.1239519 , -2.3356214 ,  0.22905351, -0.8659591 ],\n       [ 1.2248539 , -0.7608932 , -1.5419036 , -1.1351655 ],\n       [-0.4636375 , -1.613126  ,  0.7826469 , -1.2361239 ],\n       [-1.6227906 ,  1.3169725 ,  0.02268312, -2.1718407 ],\n       [ 1.0760609 , -1.0020018 , -1.1887335 , -1.7753092 ],\n       [ 1.1166463 , -1.2977825 , -1.5014501 , -1.403708  ],\n       [-1.561111  , -0.39434168, -0.79243207, -0.23716423],\n       [-2.1990833 , -1.889774  ,  2.2888198 , -2.3739154 ],\n       [-1.5951859 , -1.5779936 ,  2.1978388 , -2.5586145 ],\n       [-2.2108846 , -1.2403557 ,  1.8780161 , -1.9556092 ],\n       [-2.3761673 ,  0.9090148 , -1.0007865 , -1.4334587 ],\n       [ 0.49122727, -1.4669147 , -0.66750675, -1.4278826 ],\n       [-1.7810657 , -1.0901668 ,  2.4134748 , -2.3288934 ],\n       [ 0.29705808,  1.7409749 , -2.6376123 , -2.6852098 ],\n       [-1.7495041 ,  1.6745602 ,  0.30251345, -2.5284011 ],\n       [ 1.2035416 , -1.2261258 , -1.549764  , -2.0606701 ],\n       [-0.36014247, -1.8737152 ,  0.17629792, -1.8701525 ],\n       [-1.9249079 , -2.4694617 ,  2.2899415 , -2.243389  ],\n       [-1.2646565 ,  1.8342872 , -0.8830223 , -1.744858  ],\n       [-0.59525245, -1.1820352 , -0.8753902 , -1.0785071 ],\n       [-2.361182  , -1.5024444 ,  2.6317718 , -2.0380502 ],\n       [ 0.2617508 , -1.052297  , -1.1559186 , -1.2323987 ],\n       [-1.5474056 ,  2.0964627 , -1.4080151 , -2.2565563 ],\n       [ 0.5601643 , -1.2292936 , -0.8737921 , -1.5849771 ]],\n      dtype=float32)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_test = np.where(predictions_result > 0.5,1,0)\n",
        "result_test.shape"
      ],
      "metadata": {
        "id": "cG2H3hIEVP5y",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:45:51.666404Z",
          "iopub.execute_input": "2023-02-03T11:45:51.667336Z",
          "iopub.status.idle": "2023-02-03T11:45:51.675013Z",
          "shell.execute_reply.started": "2023-02-03T11:45:51.667296Z",
          "shell.execute_reply": "2023-02-03T11:45:51.673906Z"
        },
        "trusted": true,
        "outputId": "3f12124e-7303-412d-cc79-6c11ad6500ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(157, 4)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit = np.concatenate((X_test.to_numpy()[:,0].reshape(-1,1),result_test),axis=1)\n",
        "submit = pd.DataFrame(submit, columns=['Id']+attributes)\n",
        "submit.to_csv('test',sep=',',index=False)"
      ],
      "metadata": {
        "id": "CFqN0G-KdO6h",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:45:51.676389Z",
          "iopub.execute_input": "2023-02-03T11:45:51.677458Z",
          "iopub.status.idle": "2023-02-03T11:45:51.689365Z",
          "shell.execute_reply.started": "2023-02-03T11:45:51.677419Z",
          "shell.execute_reply": "2023-02-03T11:45:51.688731Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction"
      ],
      "metadata": {
        "id": "Gn_WiMXmAVa_",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:45:51.690402Z",
          "iopub.execute_input": "2023-02-03T11:45:51.691476Z",
          "iopub.status.idle": "2023-02-03T11:45:51.698602Z",
          "shell.execute_reply.started": "2023-02-03T11:45:51.691439Z",
          "shell.execute_reply": "2023-02-03T11:45:51.697526Z"
        },
        "trusted": true,
        "outputId": "ca8b0251-d7ff-4ed2-8ac9-d0dbd5076ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": "tensor([[ 0.5602, -1.2293, -0.8738, -1.5850]], grad_fn=<AddmmBackward0>)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict with model"
      ],
      "metadata": {
        "id": "JIfqDeMPOp8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# method to convert list of comments into predictions for each comment\n",
        "def classify_raw_comments(model, dm):\n",
        "  predictions = trainer.predict(model, datamodule=dm)\n",
        "  flattened_predictions = np.stack([torch.sigmoid(torch.Tensor(p)) for batch in predictions for p in batch])\n",
        "  return flattened_predictions"
      ],
      "metadata": {
        "id": "nU7ylR8lZZta",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:45:51.700209Z",
          "iopub.execute_input": "2023-02-03T11:45:51.700787Z",
          "iopub.status.idle": "2023-02-03T11:45:51.706712Z",
          "shell.execute_reply.started": "2023-02-03T11:45:51.700753Z",
          "shell.execute_reply": "2023-02-03T11:45:51.705697Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = classify_raw_comments(model, cov_data_module)"
      ],
      "metadata": {
        "id": "zV65QbMOZ5aU",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:45:51.708896Z",
          "iopub.execute_input": "2023-02-03T11:45:51.709213Z",
          "iopub.status.idle": "2023-02-03T11:45:54.571438Z",
          "shell.execute_reply.started": "2023-02-03T11:45:51.709187Z",
          "shell.execute_reply": "2023-02-03T11:45:54.570360Z"
        },
        "trusted": true,
        "outputId": "8015baaa-cb9b-4eb3-9613-5052c78e790f",
        "colab": {
          "referenced_widgets": [
            "0f4d961273d3432c83c4ec00940272a3"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Predicting: 22it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f4d961273d3432c83c4ec00940272a3"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = np.array(test_data[attributes])"
      ],
      "metadata": {
        "id": "t04aYi5GaFsv",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:45:54.574225Z",
          "iopub.execute_input": "2023-02-03T11:45:54.574625Z",
          "iopub.status.idle": "2023-02-03T11:45:54.581690Z",
          "shell.execute_reply.started": "2023-02-03T11:45:54.574584Z",
          "shell.execute_reply": "2023-02-03T11:45:54.580559Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "plt.figure(figsize=(15, 8))\n",
        "for i, attribute in enumerate(attributes):\n",
        "  fpr, tpr, _ = metrics.roc_curve(\n",
        "      true_labels[:,i].astype(int), predictions[:, i])\n",
        "  auc = metrics.roc_auc_score(\n",
        "      true_labels[:,i].astype(int), predictions[:, i])\n",
        "  plt.plot(fpr, tpr, label='%s %g' % (attribute, auc))\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('RoBERTa Trained on UCC Datatset - AUC ROC')"
      ],
      "metadata": {
        "id": "2h6ZoDAzafnY",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:45:54.583066Z",
          "iopub.execute_input": "2023-02-03T11:45:54.583425Z",
          "iopub.status.idle": "2023-02-03T11:45:54.845416Z",
          "shell.execute_reply.started": "2023-02-03T11:45:54.583389Z",
          "shell.execute_reply": "2023-02-03T11:45:54.844477Z"
        },
        "trusted": true,
        "outputId": "ebce7739-314c-4ffa-c94e-92eb2694244c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Text(0.5, 1.0, 'RoBERTa Trained on UCC Datatset - AUC ROC')"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1080x576 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels"
      ],
      "metadata": {
        "id": "LcJmsToRqXzO",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:45:54.846756Z",
          "iopub.execute_input": "2023-02-03T11:45:54.847346Z",
          "iopub.status.idle": "2023-02-03T11:45:54.855526Z",
          "shell.execute_reply.started": "2023-02-03T11:45:54.847308Z",
          "shell.execute_reply": "2023-02-03T11:45:54.854466Z"
        },
        "trusted": true,
        "outputId": "cc2431a8-a251-4b75-c94f-5f32bd31428e"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 41,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [1, 0, 1, 0],\n       [0, 1, 1, 0],\n       [0, 1, 1, 0],\n       [0, 1, 0, 0],\n       [0, 0, 1, 0],\n       [0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [1, 0, 0, 0],\n       [0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 1, 1],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [1, 0, 1, 0],\n       [1, 0, 0, 0],\n       [1, 1, 0, 0],\n       [0, 0, 1, 0],\n       [0, 1, 0, 0],\n       [0, 1, 1, 0],\n       [0, 0, 1, 0],\n       [1, 1, 0, 0],\n       [0, 1, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [1, 0, 1, 0],\n       [0, 0, 0, 1],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [1, 0, 0, 0],\n       [1, 1, 0, 0],\n       [1, 0, 0, 0],\n       [1, 0, 0, 0],\n       [1, 0, 0, 0],\n       [1, 1, 0, 0],\n       [0, 1, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [1, 1, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "OjH1775AqgUf",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:45:54.857121Z",
          "iopub.execute_input": "2023-02-03T11:45:54.857562Z",
          "iopub.status.idle": "2023-02-03T11:45:54.868888Z",
          "shell.execute_reply.started": "2023-02-03T11:45:54.857526Z",
          "shell.execute_reply": "2023-02-03T11:45:54.867801Z"
        },
        "trusted": true,
        "outputId": "af7e3ea1-c026-4561-f669-72bce01595e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 42,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0.09939581, 0.12502469, 0.9039512 , 0.10066989],\n       [0.10222342, 0.15076129, 0.92572063, 0.07972611],\n       [0.08803234, 0.37480372, 0.70940244, 0.09792895],\n       [0.2391305 , 0.8933317 , 0.24260905, 0.09740048],\n       [0.20291016, 0.88057137, 0.33612034, 0.07905169],\n       [0.3514572 , 0.8534749 , 0.10160481, 0.11381887],\n       [0.09592355, 0.553894  , 0.8604358 , 0.06461707],\n       [0.10309154, 0.7003905 , 0.4978803 , 0.08824693],\n       [0.76388574, 0.19351433, 0.19660054, 0.14844507],\n       [0.76631564, 0.20902848, 0.20206046, 0.12889901],\n       [0.4742086 , 0.16251956, 0.4633887 , 0.07219337],\n       [0.22111915, 0.765757  , 0.5351858 , 0.04865491],\n       [0.14562497, 0.24698307, 0.4612992 , 0.4173564 ],\n       [0.10147113, 0.1237292 , 0.9181958 , 0.08493556],\n       [0.14722183, 0.11028428, 0.6634845 , 0.1972244 ],\n       [0.11110612, 0.16725941, 0.9112252 , 0.06515769],\n       [0.16124678, 0.15916969, 0.8888665 , 0.06128298],\n       [0.7640033 , 0.17870441, 0.17482027, 0.16807614],\n       [0.5444639 , 0.79792583, 0.09879658, 0.10074949],\n       [0.09620098, 0.12871855, 0.89615554, 0.08664695],\n       [0.20605439, 0.89285004, 0.23795457, 0.12929867],\n       [0.24780782, 0.8802254 , 0.25053898, 0.08000054],\n       [0.11351225, 0.11712528, 0.9070103 , 0.08095558],\n       [0.27989677, 0.87396455, 0.20436297, 0.08049659],\n       [0.2194449 , 0.88203484, 0.2993783 , 0.07796821],\n       [0.27977994, 0.10949184, 0.8022617 , 0.0846536 ],\n       [0.09697282, 0.14027518, 0.9214905 , 0.08107709],\n       [0.39421105, 0.18189734, 0.69413286, 0.05816329],\n       [0.08950201, 0.13600062, 0.8121214 , 0.15372533],\n       [0.10832475, 0.11318714, 0.9091093 , 0.08783225],\n       [0.0900002 , 0.1391659 , 0.8818783 , 0.12531857],\n       [0.15576714, 0.35289502, 0.81954503, 0.03972014],\n       [0.1050544 , 0.10928414, 0.90874106, 0.08788642],\n       [0.7966238 , 0.31834954, 0.12870401, 0.12816718],\n       [0.53206897, 0.79045475, 0.06959502, 0.12706475],\n       [0.6674961 , 0.14621486, 0.29212996, 0.12788315],\n       [0.7780732 , 0.19834445, 0.14541268, 0.19501002],\n       [0.74683094, 0.36710778, 0.1583766 , 0.08785719],\n       [0.22466595, 0.3621213 , 0.20166151, 0.50109965],\n       [0.39594868, 0.8731205 , 0.1322792 , 0.09907135],\n       [0.27447662, 0.18134467, 0.26061594, 0.6028285 ],\n       [0.48194504, 0.09845017, 0.5417368 , 0.102867  ],\n       [0.5270275 , 0.8276702 , 0.09718855, 0.10500768],\n       [0.33709094, 0.84816146, 0.17364594, 0.07544907],\n       [0.11508813, 0.11693329, 0.91419077, 0.08304577],\n       [0.25617263, 0.2459318 , 0.15841755, 0.6041971 ],\n       [0.09453718, 0.26976267, 0.9151443 , 0.06468163],\n       [0.77185756, 0.20318566, 0.17530425, 0.1519869 ],\n       [0.407163  , 0.09991089, 0.6766446 , 0.08720739]], dtype=float32)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = np.where(predictions > 0.5,1,0)\n",
        "result"
      ],
      "metadata": {
        "id": "S0iOiwAy4nhe",
        "execution": {
          "iopub.status.busy": "2023-02-03T11:45:54.870646Z",
          "iopub.execute_input": "2023-02-03T11:45:54.871154Z",
          "iopub.status.idle": "2023-02-03T11:45:54.882073Z",
          "shell.execute_reply.started": "2023-02-03T11:45:54.871113Z",
          "shell.execute_reply": "2023-02-03T11:45:54.880913Z"
        },
        "trusted": true,
        "outputId": "351d31b7-1a69-45bc-c885-a639456c2f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 1, 0, 0],\n       [0, 1, 0, 0],\n       [0, 1, 0, 0],\n       [0, 1, 1, 0],\n       [0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 0, 0],\n       [0, 1, 1, 0],\n       [0, 0, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [1, 0, 0, 0],\n       [1, 1, 0, 0],\n       [0, 0, 1, 0],\n       [0, 1, 0, 0],\n       [0, 1, 0, 0],\n       [0, 0, 1, 0],\n       [0, 1, 0, 0],\n       [0, 1, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [1, 0, 0, 0],\n       [1, 1, 0, 0],\n       [1, 0, 0, 0],\n       [1, 0, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [0, 1, 0, 0],\n       [0, 0, 0, 1],\n       [0, 0, 1, 0],\n       [1, 1, 0, 0],\n       [0, 1, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1],\n       [0, 0, 1, 0],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous avons essayer d'implémenter notre premier CNN , malheureuselent nous n'avons pas réussi à aboutir à un résultat final par manque de temps pour comprendre son fonctionnement. "
      ],
      "metadata": {
        "id": "A3zl9BI12wEh"
      }
    }
  ]
}
